{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Credit Card Fraud Detection project is used to identify whether a new transaction is fraudulent or not  by  modeling past credit card transactions with the knowledge of the ones that turned out to be fraud. We will use various predictive models to see how accurate they are in detecting whether a transaction is a normal payment or a fraud.  \n",
    "Classification techniques are the promising solutions to detect the fraud and non-fraud transactions. Unfortunately, in a certain condition, classification techniques do not perform well when it comes to huge numbers of differences in data distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We are using the datasets provided by Kaggle. This data set includes all transactions recorded over the course of two days. As described in the dataset, the features are scaled and the names of the features are not shown due to privacy reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The dataset consists of numerical values from the 28 ‘Principal Component Analysis (PCA)’ transformed features, namely V1 to V28. Furthermore, there is no metadata about the original features provided, so pre-analysis or feature study could not be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are 284807 records. The only thing we know is that those columns that are unknown have been scaled already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are no \"Null\" values, so we don't have to work on ways to replace values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = data[data['Class'] == 1] \n",
    "valid = data[data['Class'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fraud.shape,valid.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Most of the transactions are non-fraud. If we use this dataframe as the base for our predictive models and analysis we might get a lot of errors and our algorithms will probably overfit since it will \"assume\" that most transactions are not fraud. But we don't want our model to assume, we want our model to detect patterns that give signs of fraud! \n",
    "The data set is highly skewed, consisting of 492 frauds in a total of 284,807 observations. This resulted in only 0.172% fraud cases. This skewed set is justified by the low number of fraudulent transactions."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have the data, we are using only 3 parameters for now in training the model (Time, Amount, and Class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the X and the Y from the dataset \n",
    "#X = data.drop(['Class'], axis = 1)\n",
    "X = data[['Time','Amount']]\n",
    "Y = data[\"Class\"] \n",
    "print(X.shape) \n",
    "print(Y.shape) \n",
    "# getting just the values for the sake of processing  \n",
    "# (its a numpy array with no columns) \n",
    "xData = X.values \n",
    "yData = Y.values "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We are using 80% data on training & 20% data on testing while creating the model. With this set up, We are  now ready to run the data through some models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using Skicit-learn to split data into training and testing sets \n",
    "from sklearn.model_selection import train_test_split \n",
    "# Split the data into training and testing sets \n",
    "xTrain, xTest, yTrain, yTest = train_test_split( \n",
    "        xData, yData, test_size = 0.2, random_state = 40)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The random forest is a supervised learning algorithm that randomly creates and merges multiple decision trees into one “forest.” The goal is not to rely on a single learning model, but rather a collection of decision models to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# random forest model creation \n",
    "rfc = RandomForestClassifier() \n",
    "rfc.fit(xTrain, yTrain) \n",
    "# predictions \n",
    "yPred = rfc.predict(xTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score  \n",
    "acc = accuracy_score(yTest, yPred) \n",
    "print(\"The accuracy of Render forest is {}\".format(acc)) \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TP = True Positive. Fraudulent transactions the model predicts as fraudulent.\n",
    "TN = True Negative. Normal transactions the model predicts as normal.\n",
    "FP = False Positive. Normal transactions the model predicts as fraudulent.\n",
    "FN = False Negative. Fraudulent transactions the model predicts as normal.\n",
    "\n",
    "Accuracy is the measure of correct predictions made by the model – that is, the ratio of fraud transactions classified as fraud and non-fraud classified as non-fraud to the total transactions in the test data.\n",
    "\n",
    "Lets use other Classification algorithms too!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB()\n",
    "gnb.fit(xTrain, yTrain)\n",
    "yPred=gnb.predict(xTest)\n",
    "acc = accuracy_score(yTest, yPred) \n",
    "print(\"The accuracy of Naive Bayes is {}\".format(acc)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(xTrain, yTrain)\n",
    "yPred=dummy.predict(xTest)\n",
    "acc = accuracy_score(yTest, yPred) \n",
    "print(\"The accuracy of Dummy Classifier is {}\".format(acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(xTrain, yTrain)\n",
    "yPred=svm.predict(xTest)\n",
    "acc = accuracy_score(yTest, yPred) \n",
    "print(\"The accuracy of SVM is {}\".format(acc)) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Since over 99% of our transactions are non-fraudulent, an algorithm that always predicts that the transaction is non-fraudulent would achieve an accuracy higher than 99%. Owing to such imbalance in data, an algorithm that does not do any feature analysis and predicts all the transactions as non-frauds will also achieve an accuracy of 99.829% (SVM). Therefore, accuracy is not a correct measure of efficiency in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fraud.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To create our balanced training data set, We calculated all of the fraudulent transactions in our data set . Then, We randomly selected the same number of non-fraudulent transactions and concatenated the two. There are 492 cases of fraud in our dataset so we can randomly get 492 cases of non-fraud to create our new sub dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets shuffle the data before creating the subsamples\n",
    "\n",
    "data1 = data.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_data1 = data1.loc[data1['Class'] == 1]\n",
    "non_fraud_data1 = data1.loc[data1['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_data1 = pd.concat([fraud_data1, non_fraud_data1])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_data1 = normal_distributed_data1.sample(frac=1, random_state=42)\n",
    "\n",
    "new_data1.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Down-Sizing is down-sizing method, closely related to the over-sampling method, that was considered\n",
    "in this category (rand_downsize) consists of eliminating, at random, elements of the over-sized class until it\n",
    "matches the size of the other class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution of the Classes in the subsample dataset')\n",
    "print(new_data1['Class'].value_counts()/len(new_data1))\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot('Class', data=new_data1)\n",
    "plt.title('Equally Distributed Classes', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the X and the Y from the dataset \n",
    "#X = data.drop(['Class'], axis = 1)\n",
    "X = new_data1[['Time','Amount']]\n",
    "Y = new_data1[\"Class\"] \n",
    "print(X.shape) \n",
    "print(Y.shape) \n",
    "# getting just the values for the sake of processing  \n",
    "# (its a numpy array with no columns) \n",
    "xData = X.values \n",
    "yData = Y.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using Skicit-learn to split data into training and testing sets \n",
    "from sklearn.model_selection import train_test_split \n",
    "# Split the data into training and testing sets \n",
    "xTrain, xTest, yTrain, yTest = train_test_split( \n",
    "        xData, yData, test_size = 0.2, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# random forest model creation \n",
    "rfc = RandomForestClassifier() \n",
    "rfc.fit(xTrain, yTrain) \n",
    "# predictions \n",
    "yPred = rfc.predict(xTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score  \n",
    "acc = accuracy_score(yTest, yPred) \n",
    "print(\"The accuracy of Render forest is {}\".format(acc)) \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " our classification models will not perform as accurate as previous because during under-sampling there is information loss as 492 non-fraud transaction were sampled from 284,315 non-fraud transaction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
